{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT4sxM09sso8SLl0nOe2Bf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CM-007/pythonCode_DS/blob/main/1NLP_Text_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zZG56uCZjXQ",
        "outputId": "f1e5d4a0-fdc5-4198-9872-8fb606416f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        " # Inside nltk library you will get stop word, stemming, lemmatization. So install it\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "#punkt - This tokenizer divides a text into a list of sentences by using an unsupervised algorithm\n",
        "# to build a model for abbreviation words, collocations, and words that start sentences.\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "#wordnet-WordNET is a lexical database of words in more than 200 languages in\n",
        "# which we have adjectives, adverbs, nouns,\n",
        "# and verbs grouped differently into a set of cognitive synonyms, where each word in the database is expressing its distinct concept.\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "# PortStemmer - for stemming\n",
        "# WordNetLematizer - for lemmatization\n",
        "import re # for regular expression"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAUABfViarNn",
        "outputId": "9c415221-4b30-4311-dd24-d82bd7d4b88b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text data :para=\"\"\"paste whole paragraph here\"\"\"\n",
        "para = \"\"\"‚Äî Tensor and Tensorflow: A powerful combo üí™\n",
        "The Google Brain team developed an advanced AI framework named Tensorflow years back. After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow. The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters. Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI. The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry. Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market. However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing. Welcome to the club, Google!\n",
        "\n",
        "‚Äî Tensor is an AI chip designed by AI! üò≤\n",
        "Isn‚Äôt that cool? The story is started from an article published in Nature titles ‚ÄúA graph placement methodology for fast chip design‚Äù. To design a processing chip, there is a crucial step referred to as ‚Äúfloor planning‚Äù where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied. I don‚Äôt go further into its details as I am also not an expert in hardware engineering. However, when you have a large series of choices to make with a series of constraints AI can kick in. You may remember how the AlphaGo project defeated a professional human Go player. This is exactly the same. Tensor is the real outcome of this project that is a new milestone in the AI industry. Kudos, Google!\n",
        "\n",
        "‚Äî Tensor helps us build ethical AI. üí°\n",
        "This is a double-edged sword statement. Ethical AI has various aspects from data privacy to AI for all. Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy. Why? Because the AI engine is running on the chip, and no data is sent to the cloud for further computation. On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete. I don‚Äôt want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI. We almost lost the game of model training to giant tech companies. It would be a nightmare if we lose the game on AI inference to them as well. That is why I believe ‚ÄúTensor helps us build ethical AI‚Äù is a double-edged sword.\"\"\"\n",
        "\n",
        "para"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "HrJV3WZ5a3P7",
        "outputId": "d8c07bb5-6034-44e7-db1b-bd342953ec62"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‚Äî Tensor and Tensorflow: A powerful combo üí™\\nThe Google Brain team developed an advanced AI framework named Tensorflow years back. After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow. The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters. Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI. The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry. Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market. However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing. Welcome to the club, Google!\\n\\n‚Äî Tensor is an AI chip designed by AI! üò≤\\nIsn‚Äôt that cool? The story is started from an article published in Nature titles ‚ÄúA graph placement methodology for fast chip design‚Äù. To design a processing chip, there is a crucial step referred to as ‚Äúfloor planning‚Äù where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied. I don‚Äôt go further into its details as I am also not an expert in hardware engineering. However, when you have a large series of choices to make with a series of constraints AI can kick in. You may remember how the AlphaGo project defeated a professional human Go player. This is exactly the same. Tensor is the real outcome of this project that is a new milestone in the AI industry. Kudos, Google!\\n\\n‚Äî Tensor helps us build ethical AI. üí°\\nThis is a double-edged sword statement. Ethical AI has various aspects from data privacy to AI for all. Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy. Why? Because the AI engine is running on the chip, and no data is sent to the cloud for further computation. On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete. I don‚Äôt want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI. We almost lost the game of model training to giant tech companies. It would be a nightmare if we lose the game on AI inference to them as well. That is why I believe ‚ÄúTensor helps us build ethical AI‚Äù is a double-edged sword.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(para) # returns no. of characters in sentence or paragraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huPul8UZbKGU",
        "outputId": "ce544a50-27e0-4837-a7c7-bb86fcc9e9f4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2602"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 simple example"
      ],
      "metadata": {
        "id": "H0r6Pkno525P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in this paragraph special symbols, quotation marks, punchuation symbols, emojis are present\n",
        "# these are all unnecessary things.\n",
        "# Tokenization\n",
        "# Word Tokenization\n",
        "\n",
        "document = \"We are learning tokenization in NLP\"\n",
        "nltk.word_tokenize(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DTShhELbO7F",
        "outputId": "cedf7d3d-1262-4929-8cfa-5e94b7954714"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We', 'are', 'learning', 'tokenization', 'in', 'NLP']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-ipIDQz58po",
        "outputId": "93f4b57a-be4e-4256-d2f9-deb9ac58c8b6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentence Tokenization\n",
        "sent = nltk.sent_tokenize(para)\n",
        "len(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVGnMu4e6X9g",
        "outputId": "63b2c084-a170-4fc6-d70b-8b607a5af226"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Xij2-ZB360Ra",
        "outputId": "346121df-6fb9-45f6-957c-2869787da1c2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‚Äî Tensor and Tensorflow: A powerful combo üí™\\nThe Google Brain team developed an advanced AI framework named Tensorflow years back.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Cleaning - remove unnecessary things - punctuation marks, symbols, emojis, etc. using sub()\n",
        "# Text normalization - convert each word in lower case\n",
        "#  sub() returns a string where all matching occurrences of the specified pattern are replaced by the replace string.\n",
        "corpus = [] # empty list\n",
        "\n",
        "for i in range(len(sent)):\n",
        "  txt = re.sub('[^a-zA-Z]',' ',sent[i])# except a-zA-Z remove everything from each sentence\n",
        "  txt = txt.lower()\n",
        "  corpus.append(txt)"
      ],
      "metadata": {
        "id": "sy82urZP7T0q"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-Bs-7cPAcJQ",
        "outputId": "d108395d-0092-4cee-f0b3-2956a97f938c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  tensor and tensorflow  a powerful combo   the google brain team developed an advanced ai framework named tensorflow years back ',\n",
              " 'after that  google designed its own processing unit named tensor processing unit or tpu to perform more efficiently with the tensorflow ',\n",
              " 'the invention of tpu was a revolution in ai that has significantly expedited the training of huge machine learning models with millions  or  billions  of parameters ',\n",
              " 'nevertheless  that technology could not be used in low power devices such as smartphones in edge ai ',\n",
              " 'the entrance of google into the ai chip manufacturing club for low power devices can be the next revolution in this industry ',\n",
              " 'many companies such as foghorn and blinkai are working in edge ai using currently existing ai chips in the market ',\n",
              " 'however  the efficacy that google can create by the combination of tensorflow and tensor will be game changing ',\n",
              " 'welcome to the club  google ',\n",
              " '  tensor is an ai chip designed by ai ',\n",
              " '  isn t that cool ',\n",
              " 'the story is started from an article published in nature titles  a graph placement methodology for fast chip design  ',\n",
              " 'to design a processing chip  there is a crucial step referred to as  floor planning  where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied ',\n",
              " 'i don t go further into its details as i am also not an expert in hardware engineering ',\n",
              " 'however  when you have a large series of choices to make with a series of constraints ai can kick in ',\n",
              " 'you may remember how the alphago project defeated a professional human go player ',\n",
              " 'this is exactly the same ',\n",
              " 'tensor is the real outcome of this project that is a new milestone in the ai industry ',\n",
              " 'kudos  google ',\n",
              " '  tensor helps us build ethical ai ',\n",
              " '  this is a double edged sword statement ',\n",
              " 'ethical ai has various aspects from data privacy to ai for all ',\n",
              " 'tensor helps many users have the opportunity to try the latest ai advancement while they have no concern about their privacy ',\n",
              " 'why ',\n",
              " 'because the ai engine is running on the chip  and no data is sent to the cloud for further computation ',\n",
              " 'on the other hand  the more tightly google binds ai software and hardware  the harder it will be for other companies to compete ',\n",
              " 'i don t want to see days that other companies can not even compete on performing ai inference  i e   compete on using ai ',\n",
              " 'we almost lost the game of model training to giant tech companies ',\n",
              " 'it would be a nightmare if we lose the game on ai inference to them as well ',\n",
              " 'that is why i believe  tensor helps us build ethical ai  is a double edged sword ']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 example for understanding stemming and lemmatization"
      ],
      "metadata": {
        "id": "SIt9HSEMBKfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can perform stemming and lemmatization\n",
        "#Stemming\n",
        "stemmer = PorterStemmer()\n",
        "# convert in root form"
      ],
      "metadata": {
        "id": "4iTkxyhSAgzW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('goes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "omZhZPysBV_O",
        "outputId": "f25d61c5-8433-4e22-f112-883ca8e6ab75"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'goe'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('history')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7DaWFu7MBgUm",
        "outputId": "65362c72-f4e4-4595-8c27-e483320137df"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'histori'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('finally')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cxZUOyWwBmdO",
        "outputId": "66d8dc48-f6da-4127-f75e-bfab8f9b8208"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'final'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('developed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vhDDpDTLBqjH",
        "outputId": "d246ec67-4499-4677-ef79-82855202e780"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'develop'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "  words = nltk.word_tokenize(i)\n",
        "  print(words)\n",
        "  # we get separate list for each sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQZBKyYuBuLc",
        "outputId": "40fa31e4-9a6d-431e-d6f1-2c8d79d209da"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tensor', 'and', 'tensorflow', 'a', 'powerful', 'combo', 'the', 'google', 'brain', 'team', 'developed', 'an', 'advanced', 'ai', 'framework', 'named', 'tensorflow', 'years', 'back']\n",
            "['after', 'that', 'google', 'designed', 'its', 'own', 'processing', 'unit', 'named', 'tensor', 'processing', 'unit', 'or', 'tpu', 'to', 'perform', 'more', 'efficiently', 'with', 'the', 'tensorflow']\n",
            "['the', 'invention', 'of', 'tpu', 'was', 'a', 'revolution', 'in', 'ai', 'that', 'has', 'significantly', 'expedited', 'the', 'training', 'of', 'huge', 'machine', 'learning', 'models', 'with', 'millions', 'or', 'billions', 'of', 'parameters']\n",
            "['nevertheless', 'that', 'technology', 'could', 'not', 'be', 'used', 'in', 'low', 'power', 'devices', 'such', 'as', 'smartphones', 'in', 'edge', 'ai']\n",
            "['the', 'entrance', 'of', 'google', 'into', 'the', 'ai', 'chip', 'manufacturing', 'club', 'for', 'low', 'power', 'devices', 'can', 'be', 'the', 'next', 'revolution', 'in', 'this', 'industry']\n",
            "['many', 'companies', 'such', 'as', 'foghorn', 'and', 'blinkai', 'are', 'working', 'in', 'edge', 'ai', 'using', 'currently', 'existing', 'ai', 'chips', 'in', 'the', 'market']\n",
            "['however', 'the', 'efficacy', 'that', 'google', 'can', 'create', 'by', 'the', 'combination', 'of', 'tensorflow', 'and', 'tensor', 'will', 'be', 'game', 'changing']\n",
            "['welcome', 'to', 'the', 'club', 'google']\n",
            "['tensor', 'is', 'an', 'ai', 'chip', 'designed', 'by', 'ai']\n",
            "['isn', 't', 'that', 'cool']\n",
            "['the', 'story', 'is', 'started', 'from', 'an', 'article', 'published', 'in', 'nature', 'titles', 'a', 'graph', 'placement', 'methodology', 'for', 'fast', 'chip', 'design']\n",
            "['to', 'design', 'a', 'processing', 'chip', 'there', 'is', 'a', 'crucial', 'step', 'referred', 'to', 'as', 'floor', 'planning', 'where', 'the', 'engineering', 'team', 'must', 'place', 'a', 'large', 'number', 'of', 'components', 'such', 'that', 'a', 'series', 'of', 'physical', 'requirements', 'including', 'power', 'consumption', 'and', 'performance', 'get', 'satisfied']\n",
            "['i', 'don', 't', 'go', 'further', 'into', 'its', 'details', 'as', 'i', 'am', 'also', 'not', 'an', 'expert', 'in', 'hardware', 'engineering']\n",
            "['however', 'when', 'you', 'have', 'a', 'large', 'series', 'of', 'choices', 'to', 'make', 'with', 'a', 'series', 'of', 'constraints', 'ai', 'can', 'kick', 'in']\n",
            "['you', 'may', 'remember', 'how', 'the', 'alphago', 'project', 'defeated', 'a', 'professional', 'human', 'go', 'player']\n",
            "['this', 'is', 'exactly', 'the', 'same']\n",
            "['tensor', 'is', 'the', 'real', 'outcome', 'of', 'this', 'project', 'that', 'is', 'a', 'new', 'milestone', 'in', 'the', 'ai', 'industry']\n",
            "['kudos', 'google']\n",
            "['tensor', 'helps', 'us', 'build', 'ethical', 'ai']\n",
            "['this', 'is', 'a', 'double', 'edged', 'sword', 'statement']\n",
            "['ethical', 'ai', 'has', 'various', 'aspects', 'from', 'data', 'privacy', 'to', 'ai', 'for', 'all']\n",
            "['tensor', 'helps', 'many', 'users', 'have', 'the', 'opportunity', 'to', 'try', 'the', 'latest', 'ai', 'advancement', 'while', 'they', 'have', 'no', 'concern', 'about', 'their', 'privacy']\n",
            "['why']\n",
            "['because', 'the', 'ai', 'engine', 'is', 'running', 'on', 'the', 'chip', 'and', 'no', 'data', 'is', 'sent', 'to', 'the', 'cloud', 'for', 'further', 'computation']\n",
            "['on', 'the', 'other', 'hand', 'the', 'more', 'tightly', 'google', 'binds', 'ai', 'software', 'and', 'hardware', 'the', 'harder', 'it', 'will', 'be', 'for', 'other', 'companies', 'to', 'compete']\n",
            "['i', 'don', 't', 'want', 'to', 'see', 'days', 'that', 'other', 'companies', 'can', 'not', 'even', 'compete', 'on', 'performing', 'ai', 'inference', 'i', 'e', 'compete', 'on', 'using', 'ai']\n",
            "['we', 'almost', 'lost', 'the', 'game', 'of', 'model', 'training', 'to', 'giant', 'tech', 'companies']\n",
            "['it', 'would', 'be', 'a', 'nightmare', 'if', 'we', 'lose', 'the', 'game', 'on', 'ai', 'inference', 'to', 'them', 'as', 'well']\n",
            "['that', 'is', 'why', 'i', 'believe', 'tensor', 'helps', 'us', 'build', 'ethical', 'ai', 'is', 'a', 'double', 'edged', 'sword']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Tokenization, stemming and stop word removal\n",
        "\n",
        "for i in corpus:\n",
        "  words = nltk.word_tokenize(i) # for each sentence in corpus perform word tokenization\n",
        "  for i in words: # for each unique value inside word\n",
        "    if i not in set(stopwords.words('english')): # will check words in stopwords from set of english stopwords\n",
        "      print(stemmer.stem(i)) # the words whch are not present in stopwords set print by performing stemming using stem() function.\n",
        "      # powerful - power, google-googl ... doen't make sense"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JYHprqUCRw5",
        "outputId": "863137c7-26f2-4d20-c735-5aa297dabdd4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor\n",
            "tensorflow\n",
            "power\n",
            "combo\n",
            "googl\n",
            "brain\n",
            "team\n",
            "develop\n",
            "advanc\n",
            "ai\n",
            "framework\n",
            "name\n",
            "tensorflow\n",
            "year\n",
            "back\n",
            "googl\n",
            "design\n",
            "process\n",
            "unit\n",
            "name\n",
            "tensor\n",
            "process\n",
            "unit\n",
            "tpu\n",
            "perform\n",
            "effici\n",
            "tensorflow\n",
            "invent\n",
            "tpu\n",
            "revolut\n",
            "ai\n",
            "significantli\n",
            "expedit\n",
            "train\n",
            "huge\n",
            "machin\n",
            "learn\n",
            "model\n",
            "million\n",
            "billion\n",
            "paramet\n",
            "nevertheless\n",
            "technolog\n",
            "could\n",
            "use\n",
            "low\n",
            "power\n",
            "devic\n",
            "smartphon\n",
            "edg\n",
            "ai\n",
            "entranc\n",
            "googl\n",
            "ai\n",
            "chip\n",
            "manufactur\n",
            "club\n",
            "low\n",
            "power\n",
            "devic\n",
            "next\n",
            "revolut\n",
            "industri\n",
            "mani\n",
            "compani\n",
            "foghorn\n",
            "blinkai\n",
            "work\n",
            "edg\n",
            "ai\n",
            "use\n",
            "current\n",
            "exist\n",
            "ai\n",
            "chip\n",
            "market\n",
            "howev\n",
            "efficaci\n",
            "googl\n",
            "creat\n",
            "combin\n",
            "tensorflow\n",
            "tensor\n",
            "game\n",
            "chang\n",
            "welcom\n",
            "club\n",
            "googl\n",
            "tensor\n",
            "ai\n",
            "chip\n",
            "design\n",
            "ai\n",
            "cool\n",
            "stori\n",
            "start\n",
            "articl\n",
            "publish\n",
            "natur\n",
            "titl\n",
            "graph\n",
            "placement\n",
            "methodolog\n",
            "fast\n",
            "chip\n",
            "design\n",
            "design\n",
            "process\n",
            "chip\n",
            "crucial\n",
            "step\n",
            "refer\n",
            "floor\n",
            "plan\n",
            "engin\n",
            "team\n",
            "must\n",
            "place\n",
            "larg\n",
            "number\n",
            "compon\n",
            "seri\n",
            "physic\n",
            "requir\n",
            "includ\n",
            "power\n",
            "consumpt\n",
            "perform\n",
            "get\n",
            "satisfi\n",
            "go\n",
            "detail\n",
            "also\n",
            "expert\n",
            "hardwar\n",
            "engin\n",
            "howev\n",
            "larg\n",
            "seri\n",
            "choic\n",
            "make\n",
            "seri\n",
            "constraint\n",
            "ai\n",
            "kick\n",
            "may\n",
            "rememb\n",
            "alphago\n",
            "project\n",
            "defeat\n",
            "profession\n",
            "human\n",
            "go\n",
            "player\n",
            "exactli\n",
            "tensor\n",
            "real\n",
            "outcom\n",
            "project\n",
            "new\n",
            "mileston\n",
            "ai\n",
            "industri\n",
            "kudo\n",
            "googl\n",
            "tensor\n",
            "help\n",
            "us\n",
            "build\n",
            "ethic\n",
            "ai\n",
            "doubl\n",
            "edg\n",
            "sword\n",
            "statement\n",
            "ethic\n",
            "ai\n",
            "variou\n",
            "aspect\n",
            "data\n",
            "privaci\n",
            "ai\n",
            "tensor\n",
            "help\n",
            "mani\n",
            "user\n",
            "opportun\n",
            "tri\n",
            "latest\n",
            "ai\n",
            "advanc\n",
            "concern\n",
            "privaci\n",
            "ai\n",
            "engin\n",
            "run\n",
            "chip\n",
            "data\n",
            "sent\n",
            "cloud\n",
            "comput\n",
            "hand\n",
            "tightli\n",
            "googl\n",
            "bind\n",
            "ai\n",
            "softwar\n",
            "hardwar\n",
            "harder\n",
            "compani\n",
            "compet\n",
            "want\n",
            "see\n",
            "day\n",
            "compani\n",
            "even\n",
            "compet\n",
            "perform\n",
            "ai\n",
            "infer\n",
            "e\n",
            "compet\n",
            "use\n",
            "ai\n",
            "almost\n",
            "lost\n",
            "game\n",
            "model\n",
            "train\n",
            "giant\n",
            "tech\n",
            "compani\n",
            "would\n",
            "nightmar\n",
            "lose\n",
            "game\n",
            "ai\n",
            "infer\n",
            "well\n",
            "believ\n",
            "tensor\n",
            "help\n",
            "us\n",
            "build\n",
            "ethic\n",
            "ai\n",
            "doubl\n",
            "edg\n",
            "sword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "lemma = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "iSgFpYQBDReV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize('google')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FIx4BsOoDvFf",
        "outputId": "abcc70eb-00a0-4bf1-dda5-cd0428eae345"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'google'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize('historical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "59k1-zuhD2zm",
        "outputId": "fb012903-0be9-4c25-b3a7-18df66dc583d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'historical'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize('coming')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-WTnvG7uD6UA",
        "outputId": "b9964c97-c193-4dcf-8e05-ee01e508301b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'coming'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "  words = nltk.word_tokenize(i)\n",
        "  for i in words:\n",
        "    if i not in set(stopwords.words('english')):\n",
        "      print(lemma.lemmatize(i))\n",
        "      #proper google, powerful.. meaningful words are returned by lemmatization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l73gNtTED8ef",
        "outputId": "7770eb81-b8e3-44b7-9b4d-1766baf39fec"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor\n",
            "tensorflow\n",
            "powerful\n",
            "combo\n",
            "google\n",
            "brain\n",
            "team\n",
            "developed\n",
            "advanced\n",
            "ai\n",
            "framework\n",
            "named\n",
            "tensorflow\n",
            "year\n",
            "back\n",
            "google\n",
            "designed\n",
            "processing\n",
            "unit\n",
            "named\n",
            "tensor\n",
            "processing\n",
            "unit\n",
            "tpu\n",
            "perform\n",
            "efficiently\n",
            "tensorflow\n",
            "invention\n",
            "tpu\n",
            "revolution\n",
            "ai\n",
            "significantly\n",
            "expedited\n",
            "training\n",
            "huge\n",
            "machine\n",
            "learning\n",
            "model\n",
            "million\n",
            "billion\n",
            "parameter\n",
            "nevertheless\n",
            "technology\n",
            "could\n",
            "used\n",
            "low\n",
            "power\n",
            "device\n",
            "smartphones\n",
            "edge\n",
            "ai\n",
            "entrance\n",
            "google\n",
            "ai\n",
            "chip\n",
            "manufacturing\n",
            "club\n",
            "low\n",
            "power\n",
            "device\n",
            "next\n",
            "revolution\n",
            "industry\n",
            "many\n",
            "company\n",
            "foghorn\n",
            "blinkai\n",
            "working\n",
            "edge\n",
            "ai\n",
            "using\n",
            "currently\n",
            "existing\n",
            "ai\n",
            "chip\n",
            "market\n",
            "however\n",
            "efficacy\n",
            "google\n",
            "create\n",
            "combination\n",
            "tensorflow\n",
            "tensor\n",
            "game\n",
            "changing\n",
            "welcome\n",
            "club\n",
            "google\n",
            "tensor\n",
            "ai\n",
            "chip\n",
            "designed\n",
            "ai\n",
            "cool\n",
            "story\n",
            "started\n",
            "article\n",
            "published\n",
            "nature\n",
            "title\n",
            "graph\n",
            "placement\n",
            "methodology\n",
            "fast\n",
            "chip\n",
            "design\n",
            "design\n",
            "processing\n",
            "chip\n",
            "crucial\n",
            "step\n",
            "referred\n",
            "floor\n",
            "planning\n",
            "engineering\n",
            "team\n",
            "must\n",
            "place\n",
            "large\n",
            "number\n",
            "component\n",
            "series\n",
            "physical\n",
            "requirement\n",
            "including\n",
            "power\n",
            "consumption\n",
            "performance\n",
            "get\n",
            "satisfied\n",
            "go\n",
            "detail\n",
            "also\n",
            "expert\n",
            "hardware\n",
            "engineering\n",
            "however\n",
            "large\n",
            "series\n",
            "choice\n",
            "make\n",
            "series\n",
            "constraint\n",
            "ai\n",
            "kick\n",
            "may\n",
            "remember\n",
            "alphago\n",
            "project\n",
            "defeated\n",
            "professional\n",
            "human\n",
            "go\n",
            "player\n",
            "exactly\n",
            "tensor\n",
            "real\n",
            "outcome\n",
            "project\n",
            "new\n",
            "milestone\n",
            "ai\n",
            "industry\n",
            "kudos\n",
            "google\n",
            "tensor\n",
            "help\n",
            "u\n",
            "build\n",
            "ethical\n",
            "ai\n",
            "double\n",
            "edged\n",
            "sword\n",
            "statement\n",
            "ethical\n",
            "ai\n",
            "various\n",
            "aspect\n",
            "data\n",
            "privacy\n",
            "ai\n",
            "tensor\n",
            "help\n",
            "many\n",
            "user\n",
            "opportunity\n",
            "try\n",
            "latest\n",
            "ai\n",
            "advancement\n",
            "concern\n",
            "privacy\n",
            "ai\n",
            "engine\n",
            "running\n",
            "chip\n",
            "data\n",
            "sent\n",
            "cloud\n",
            "computation\n",
            "hand\n",
            "tightly\n",
            "google\n",
            "bind\n",
            "ai\n",
            "software\n",
            "hardware\n",
            "harder\n",
            "company\n",
            "compete\n",
            "want\n",
            "see\n",
            "day\n",
            "company\n",
            "even\n",
            "compete\n",
            "performing\n",
            "ai\n",
            "inference\n",
            "e\n",
            "compete\n",
            "using\n",
            "ai\n",
            "almost\n",
            "lost\n",
            "game\n",
            "model\n",
            "training\n",
            "giant\n",
            "tech\n",
            "company\n",
            "would\n",
            "nightmare\n",
            "lose\n",
            "game\n",
            "ai\n",
            "inference\n",
            "well\n",
            "believe\n",
            "tensor\n",
            "help\n",
            "u\n",
            "build\n",
            "ethical\n",
            "ai\n",
            "double\n",
            "edged\n",
            "sword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Extraction**"
      ],
      "metadata": {
        "id": "5OCtGASUEiVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert text data to BoW (Bag of Words) or TFIDF (Term Frequency - Inverse Document Frequency)\n",
        "# CountVectorizer - for BoW, TfidfVectorizer - for TFIDF\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "usQfbNRcEMid"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cv = CountVectorizer() # BoW - frequency will be displayed\n",
        "# Bag of Words (BoW) simply counts the frequency of words in a document.\n",
        "#cv = CountVectorizer(binary=True) # only binary weight will be displayed i.e. present or not\n",
        "x = cv.fit_transform(corpus)#\n",
        "cv.vocabulary_ # following words are taken as columns, no. represents index of each word\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P980uXJeE3G2",
        "outputId": "b3213cfb-7ddf-4cba-c285-2be0a06af5bb"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tensor': 180,\n",
              " 'and': 11,\n",
              " 'tensorflow': 181,\n",
              " 'powerful': 151,\n",
              " 'combo': 34,\n",
              " 'the': 183,\n",
              " 'google': 81,\n",
              " 'brain': 23,\n",
              " 'team': 177,\n",
              " 'developed': 53,\n",
              " 'an': 10,\n",
              " 'advanced': 1,\n",
              " 'ai': 4,\n",
              " 'framework': 74,\n",
              " 'named': 125,\n",
              " 'years': 214,\n",
              " 'back': 16,\n",
              " 'after': 3,\n",
              " 'that': 182,\n",
              " 'designed': 51,\n",
              " 'its': 103,\n",
              " 'own': 140,\n",
              " 'processing': 153,\n",
              " 'unit': 195,\n",
              " 'or': 137,\n",
              " 'tpu': 192,\n",
              " 'to': 191,\n",
              " 'perform': 142,\n",
              " 'more': 123,\n",
              " 'efficiently': 60,\n",
              " 'with': 211,\n",
              " 'invention': 99,\n",
              " 'of': 134,\n",
              " 'was': 202,\n",
              " 'revolution': 161,\n",
              " 'in': 94,\n",
              " 'has': 86,\n",
              " 'significantly': 168,\n",
              " 'expedited': 68,\n",
              " 'training': 193,\n",
              " 'huge': 91,\n",
              " 'machine': 112,\n",
              " 'learning': 108,\n",
              " 'models': 122,\n",
              " 'millions': 120,\n",
              " 'billions': 20,\n",
              " 'parameters': 141,\n",
              " 'nevertheless': 127,\n",
              " 'technology': 179,\n",
              " 'could': 43,\n",
              " 'not': 132,\n",
              " 'be': 17,\n",
              " 'used': 197,\n",
              " 'low': 111,\n",
              " 'power': 150,\n",
              " 'devices': 54,\n",
              " 'such': 175,\n",
              " 'as': 14,\n",
              " 'smartphones': 169,\n",
              " 'edge': 57,\n",
              " 'entrance': 63,\n",
              " 'into': 98,\n",
              " 'chip': 28,\n",
              " 'manufacturing': 114,\n",
              " 'club': 32,\n",
              " 'for': 73,\n",
              " 'can': 26,\n",
              " 'next': 129,\n",
              " 'this': 188,\n",
              " 'industry': 96,\n",
              " 'many': 115,\n",
              " 'companies': 35,\n",
              " 'foghorn': 72,\n",
              " 'blinkai': 22,\n",
              " 'are': 12,\n",
              " 'working': 212,\n",
              " 'using': 199,\n",
              " 'currently': 46,\n",
              " 'existing': 67,\n",
              " 'chips': 29,\n",
              " 'market': 116,\n",
              " 'however': 90,\n",
              " 'efficacy': 59,\n",
              " 'create': 44,\n",
              " 'by': 25,\n",
              " 'combination': 33,\n",
              " 'will': 210,\n",
              " 'game': 77,\n",
              " 'changing': 27,\n",
              " 'welcome': 204,\n",
              " 'is': 100,\n",
              " 'isn': 101,\n",
              " 'cool': 42,\n",
              " 'story': 174,\n",
              " 'started': 171,\n",
              " 'from': 75,\n",
              " 'article': 13,\n",
              " 'published': 156,\n",
              " 'nature': 126,\n",
              " 'titles': 190,\n",
              " 'graph': 82,\n",
              " 'placement': 147,\n",
              " 'methodology': 118,\n",
              " 'fast': 70,\n",
              " 'design': 50,\n",
              " 'there': 186,\n",
              " 'crucial': 45,\n",
              " 'step': 173,\n",
              " 'referred': 158,\n",
              " 'floor': 71,\n",
              " 'planning': 148,\n",
              " 'where': 207,\n",
              " 'engineering': 62,\n",
              " 'must': 124,\n",
              " 'place': 146,\n",
              " 'large': 106,\n",
              " 'number': 133,\n",
              " 'components': 37,\n",
              " 'series': 167,\n",
              " 'physical': 145,\n",
              " 'requirements': 160,\n",
              " 'including': 95,\n",
              " 'consumption': 41,\n",
              " 'performance': 143,\n",
              " 'get': 78,\n",
              " 'satisfied': 164,\n",
              " 'don': 55,\n",
              " 'go': 80,\n",
              " 'further': 76,\n",
              " 'details': 52,\n",
              " 'am': 9,\n",
              " 'also': 8,\n",
              " 'expert': 69,\n",
              " 'hardware': 85,\n",
              " 'when': 206,\n",
              " 'you': 215,\n",
              " 'have': 87,\n",
              " 'choices': 30,\n",
              " 'make': 113,\n",
              " 'constraints': 40,\n",
              " 'kick': 104,\n",
              " 'may': 117,\n",
              " 'remember': 159,\n",
              " 'how': 89,\n",
              " 'alphago': 7,\n",
              " 'project': 155,\n",
              " 'defeated': 49,\n",
              " 'professional': 154,\n",
              " 'human': 92,\n",
              " 'player': 149,\n",
              " 'exactly': 66,\n",
              " 'same': 163,\n",
              " 'real': 157,\n",
              " 'outcome': 139,\n",
              " 'new': 128,\n",
              " 'milestone': 119,\n",
              " 'kudos': 105,\n",
              " 'helps': 88,\n",
              " 'us': 196,\n",
              " 'build': 24,\n",
              " 'ethical': 64,\n",
              " 'double': 56,\n",
              " 'edged': 58,\n",
              " 'sword': 176,\n",
              " 'statement': 172,\n",
              " 'various': 200,\n",
              " 'aspects': 15,\n",
              " 'data': 47,\n",
              " 'privacy': 152,\n",
              " 'all': 5,\n",
              " 'users': 198,\n",
              " 'opportunity': 136,\n",
              " 'try': 194,\n",
              " 'latest': 107,\n",
              " 'advancement': 2,\n",
              " 'while': 208,\n",
              " 'they': 187,\n",
              " 'no': 131,\n",
              " 'concern': 39,\n",
              " 'about': 0,\n",
              " 'their': 184,\n",
              " 'why': 209,\n",
              " 'because': 18,\n",
              " 'engine': 61,\n",
              " 'running': 162,\n",
              " 'on': 135,\n",
              " 'sent': 166,\n",
              " 'cloud': 31,\n",
              " 'computation': 38,\n",
              " 'other': 138,\n",
              " 'hand': 83,\n",
              " 'tightly': 189,\n",
              " 'binds': 21,\n",
              " 'software': 170,\n",
              " 'harder': 84,\n",
              " 'it': 102,\n",
              " 'compete': 36,\n",
              " 'want': 201,\n",
              " 'see': 165,\n",
              " 'days': 48,\n",
              " 'even': 65,\n",
              " 'performing': 144,\n",
              " 'inference': 97,\n",
              " 'we': 203,\n",
              " 'almost': 6,\n",
              " 'lost': 110,\n",
              " 'model': 121,\n",
              " 'giant': 79,\n",
              " 'tech': 178,\n",
              " 'would': 213,\n",
              " 'nightmare': 130,\n",
              " 'if': 93,\n",
              " 'lose': 109,\n",
              " 'them': 185,\n",
              " 'well': 205,\n",
              " 'believe': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us see what type of BoW it has created. BoW - gives frequency of term in document, Binary Weight - tells word is present or not\n",
        "# We can't directly print matrix x. so we need to convert it to array\n",
        "x[0].toarray() # BoW for 1st sentence,    'tensorflow': index is: 181. It occurred 2 times in 1st sentence. Check corpus[0].\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq6RdJY6FIc9",
        "outputId": "ed7c786d-2f46-4d37-b523-be95f13aab87"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0] # for this sentence above BoW is created. Why does it contain more values than the no. of words in this sentence?\n",
        "# Column contains all unique words."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "LoLmnvmxFtEm",
        "outputId": "1bfd4649-1c9d-4344-8ec0-060a889bc9fb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  tensor and tensorflow  a powerful combo   the google brain team developed an advanced ai framework named tensorflow years back '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert array into dataframe, DTM - Document Term Matrix\n",
        "x = pd.DataFrame(x.toarray(),columns=cv.get_feature_names_out())\n",
        "x\n",
        "# for 'advanced' word index was 1 so it is present at colummn index no. 1\n",
        "# in 5th document word 'ai' is occuring for 2 times.\n",
        "# BoW - gives you frequency\n",
        "# Binary weights - tells whether word is present or not\n",
        "# If you don't want to print frequency in dataframe, keep binary=True in 'cv = CountVectonizer(binary=True)'\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iA_RHCEsGr_I",
        "outputId": "f61c5bf0-7f27-4200-ae37-6972403e782d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    about  advanced  advancement  after  ai  all  almost  alphago  also  am  \\\n",
              "0       0         1            0      0   1    0       0        0     0   0   \n",
              "1       0         0            0      1   0    0       0        0     0   0   \n",
              "2       0         0            0      0   1    0       0        0     0   0   \n",
              "3       0         0            0      0   1    0       0        0     0   0   \n",
              "4       0         0            0      0   1    0       0        0     0   0   \n",
              "5       0         0            0      0   2    0       0        0     0   0   \n",
              "6       0         0            0      0   0    0       0        0     0   0   \n",
              "7       0         0            0      0   0    0       0        0     0   0   \n",
              "8       0         0            0      0   2    0       0        0     0   0   \n",
              "9       0         0            0      0   0    0       0        0     0   0   \n",
              "10      0         0            0      0   0    0       0        0     0   0   \n",
              "11      0         0            0      0   0    0       0        0     0   0   \n",
              "12      0         0            0      0   0    0       0        0     1   1   \n",
              "13      0         0            0      0   1    0       0        0     0   0   \n",
              "14      0         0            0      0   0    0       0        1     0   0   \n",
              "15      0         0            0      0   0    0       0        0     0   0   \n",
              "16      0         0            0      0   1    0       0        0     0   0   \n",
              "17      0         0            0      0   0    0       0        0     0   0   \n",
              "18      0         0            0      0   1    0       0        0     0   0   \n",
              "19      0         0            0      0   0    0       0        0     0   0   \n",
              "20      0         0            0      0   2    1       0        0     0   0   \n",
              "21      1         0            1      0   1    0       0        0     0   0   \n",
              "22      0         0            0      0   0    0       0        0     0   0   \n",
              "23      0         0            0      0   1    0       0        0     0   0   \n",
              "24      0         0            0      0   1    0       0        0     0   0   \n",
              "25      0         0            0      0   2    0       0        0     0   0   \n",
              "26      0         0            0      0   0    0       1        0     0   0   \n",
              "27      0         0            0      0   1    0       0        0     0   0   \n",
              "28      0         0            0      0   1    0       0        0     0   0   \n",
              "\n",
              "    ...  when  where  while  why  will  with  working  would  years  you  \n",
              "0   ...     0      0      0    0     0     0        0      0      1    0  \n",
              "1   ...     0      0      0    0     0     1        0      0      0    0  \n",
              "2   ...     0      0      0    0     0     1        0      0      0    0  \n",
              "3   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "4   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "5   ...     0      0      0    0     0     0        1      0      0    0  \n",
              "6   ...     0      0      0    0     1     0        0      0      0    0  \n",
              "7   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "8   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "9   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "10  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "11  ...     0      1      0    0     0     0        0      0      0    0  \n",
              "12  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "13  ...     1      0      0    0     0     1        0      0      0    1  \n",
              "14  ...     0      0      0    0     0     0        0      0      0    1  \n",
              "15  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "16  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "17  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "18  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "19  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "20  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "21  ...     0      0      1    0     0     0        0      0      0    0  \n",
              "22  ...     0      0      0    1     0     0        0      0      0    0  \n",
              "23  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "24  ...     0      0      0    0     1     0        0      0      0    0  \n",
              "25  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "26  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "27  ...     0      0      0    0     0     0        0      1      0    0  \n",
              "28  ...     0      0      0    1     0     0        0      0      0    0  \n",
              "\n",
              "[29 rows x 216 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e4a2c49-ef8f-4e9a-ae03-d2f269e2c57c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>about</th>\n",
              "      <th>advanced</th>\n",
              "      <th>advancement</th>\n",
              "      <th>after</th>\n",
              "      <th>ai</th>\n",
              "      <th>all</th>\n",
              "      <th>almost</th>\n",
              "      <th>alphago</th>\n",
              "      <th>also</th>\n",
              "      <th>am</th>\n",
              "      <th>...</th>\n",
              "      <th>when</th>\n",
              "      <th>where</th>\n",
              "      <th>while</th>\n",
              "      <th>why</th>\n",
              "      <th>will</th>\n",
              "      <th>with</th>\n",
              "      <th>working</th>\n",
              "      <th>would</th>\n",
              "      <th>years</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29 rows √ó 216 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e4a2c49-ef8f-4e9a-ae03-d2f269e2c57c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e4a2c49-ef8f-4e9a-ae03-d2f269e2c57c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e4a2c49-ef8f-4e9a-ae03-d2f269e2c57c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-02d5c088-b18a-4553-ad9f-c9b66178fe59\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02d5c088-b18a-4553-ad9f-c9b66178fe59')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-02d5c088-b18a-4553-ad9f-c9b66178fe59 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF-IDF**"
      ],
      "metadata": {
        "id": "Q-DxhmN-HnGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf = TfidfVectorizer() # instance\n",
        "x = tf.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "CEGEVhlZHJWa"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.toarray()\n",
        "# calculate weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfA9sJPmHsI9",
        "outputId": "9b11807e-852f-4540-c1a1-8bb21e468368"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.26420014, 0.        , ..., 0.        , 0.26420014,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.29867304, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert it into dataframe\n",
        "x = pd.DataFrame(x.toarray(),columns = tf.get_feature_names_out()) #get_feature_names_out() - gives you list of unique words inside corpus\n",
        "x # here we are retaining information related to the frequency of words, TDM-Term Document Frequency\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zLHn33C8HzTe",
        "outputId": "987bd9ed-93a5-48e1-ba4c-bd1d480247ca"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       about  advanced  advancement     after        ai       all    almost  \\\n",
              "0   0.000000    0.2642     0.000000  0.000000  0.111720  0.000000  0.000000   \n",
              "1   0.000000    0.0000     0.000000  0.230918  0.000000  0.000000  0.000000   \n",
              "2   0.000000    0.0000     0.000000  0.000000  0.093004  0.000000  0.000000   \n",
              "3   0.000000    0.0000     0.000000  0.000000  0.120739  0.000000  0.000000   \n",
              "4   0.000000    0.0000     0.000000  0.000000  0.113623  0.000000  0.000000   \n",
              "5   0.000000    0.0000     0.000000  0.000000  0.219569  0.000000  0.000000   \n",
              "6   0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "7   0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "8   0.000000    0.0000     0.000000  0.000000  0.419187  0.000000  0.000000   \n",
              "9   0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "10  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "11  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "12  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "13  0.000000    0.0000     0.000000  0.000000  0.109396  0.000000  0.000000   \n",
              "14  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "15  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "16  0.000000    0.0000     0.000000  0.000000  0.134883  0.000000  0.000000   \n",
              "17  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "18  0.000000    0.0000     0.000000  0.000000  0.227965  0.000000  0.000000   \n",
              "19  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "20  0.000000    0.0000     0.000000  0.000000  0.293347  0.346861  0.000000   \n",
              "21  0.237845    0.0000     0.237845  0.000000  0.100575  0.000000  0.000000   \n",
              "22  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "23  0.000000    0.0000     0.000000  0.000000  0.114125  0.000000  0.000000   \n",
              "24  0.000000    0.0000     0.000000  0.000000  0.102456  0.000000  0.000000   \n",
              "25  0.000000    0.0000     0.000000  0.000000  0.206884  0.000000  0.000000   \n",
              "26  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.340215   \n",
              "27  0.000000    0.0000     0.000000  0.000000  0.126297  0.000000  0.000000   \n",
              "28  0.000000    0.0000     0.000000  0.000000  0.138310  0.000000  0.000000   \n",
              "\n",
              "     alphago     also       am  ...      when     where     while       why  \\\n",
              "0   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "1   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "2   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "3   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "4   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "5   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "6   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "7   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "8   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "9   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "10  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "11  0.000000  0.00000  0.00000  ...  0.000000  0.185738  0.000000  0.000000   \n",
              "12  0.000000  0.29324  0.29324  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "13  0.000000  0.00000  0.00000  ...  0.258705  0.000000  0.000000  0.000000   \n",
              "14  0.307936  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "15  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "16  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "17  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "18  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "19  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "20  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "21  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.237845  0.000000   \n",
              "22  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  1.000000   \n",
              "23  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "24  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "25  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "26  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "27  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "28  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.291317   \n",
              "\n",
              "        will      with   working     would   years       you  \n",
              "0   0.000000  0.000000  0.000000  0.000000  0.2642  0.000000  \n",
              "1   0.000000  0.187753  0.000000  0.000000  0.0000  0.000000  \n",
              "2   0.000000  0.178827  0.000000  0.000000  0.0000  0.000000  \n",
              "3   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "4   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "5   0.000000  0.000000  0.259624  0.000000  0.0000  0.000000  \n",
              "6   0.264670  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "7   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "8   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "9   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "10  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "11  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "12  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "13  0.000000  0.210345  0.000000  0.000000  0.0000  0.230416  \n",
              "14  0.000000  0.000000  0.000000  0.000000  0.0000  0.274264  \n",
              "15  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "16  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "17  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "18  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "19  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "20  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "21  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "22  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "23  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "24  0.215799  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "25  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "26  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "27  0.000000  0.000000  0.000000  0.298673  0.0000  0.000000  \n",
              "28  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "\n",
              "[29 rows x 216 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6cfd28e-4ab9-4861-b9c3-23d39438a22d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>about</th>\n",
              "      <th>advanced</th>\n",
              "      <th>advancement</th>\n",
              "      <th>after</th>\n",
              "      <th>ai</th>\n",
              "      <th>all</th>\n",
              "      <th>almost</th>\n",
              "      <th>alphago</th>\n",
              "      <th>also</th>\n",
              "      <th>am</th>\n",
              "      <th>...</th>\n",
              "      <th>when</th>\n",
              "      <th>where</th>\n",
              "      <th>while</th>\n",
              "      <th>why</th>\n",
              "      <th>will</th>\n",
              "      <th>with</th>\n",
              "      <th>working</th>\n",
              "      <th>would</th>\n",
              "      <th>years</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2642</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.230918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.187753</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.093004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178827</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.113623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.219569</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.419187</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.185738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.29324</td>\n",
              "      <td>0.29324</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.109396</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.258705</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.210345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.230416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307936</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.274264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.134883</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.227965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.293347</td>\n",
              "      <td>0.346861</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.237845</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.237845</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100575</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.237845</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.102456</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.215799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.206884</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.340215</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.126297</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.298673</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138310</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291317</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29 rows √ó 216 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6cfd28e-4ab9-4861-b9c3-23d39438a22d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6cfd28e-4ab9-4861-b9c3-23d39438a22d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6cfd28e-4ab9-4861-b9c3-23d39438a22d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19dbc70d-0e49-4ad8-8182-c7f1f3b0d912\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19dbc70d-0e49-4ad8-8182-c7f1f3b0d912')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19dbc70d-0e49-4ad8-8182-c7f1f3b0d912 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX33By0zIAip",
        "outputId": "abc80cf3-b9b6-487d-f9ab-5fd66c4178b3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHQyVTCKIFCK",
        "outputId": "a26aa88e-ec65-4f40-fef9-ca008f791d44"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['about', 'advanced', 'advancement', 'after', 'ai', 'all', 'almost',\n",
              "       'alphago', 'also', 'am', 'an', 'and', 'are', 'article', 'as',\n",
              "       'aspects', 'back', 'be', 'because', 'believe', 'billions', 'binds',\n",
              "       'blinkai', 'brain', 'build', 'by', 'can', 'changing', 'chip',\n",
              "       'chips', 'choices', 'cloud', 'club', 'combination', 'combo',\n",
              "       'companies', 'compete', 'components', 'computation', 'concern',\n",
              "       'constraints', 'consumption', 'cool', 'could', 'create', 'crucial',\n",
              "       'currently', 'data', 'days', 'defeated', 'design', 'designed',\n",
              "       'details', 'developed', 'devices', 'don', 'double', 'edge',\n",
              "       'edged', 'efficacy', 'efficiently', 'engine', 'engineering',\n",
              "       'entrance', 'ethical', 'even', 'exactly', 'existing', 'expedited',\n",
              "       'expert', 'fast', 'floor', 'foghorn', 'for', 'framework', 'from',\n",
              "       'further', 'game', 'get', 'giant', 'go', 'google', 'graph', 'hand',\n",
              "       'harder', 'hardware', 'has', 'have', 'helps', 'how', 'however',\n",
              "       'huge', 'human', 'if', 'in', 'including', 'industry', 'inference',\n",
              "       'into', 'invention', 'is', 'isn', 'it', 'its', 'kick', 'kudos',\n",
              "       'large', 'latest', 'learning', 'lose', 'lost', 'low', 'machine',\n",
              "       'make', 'manufacturing', 'many', 'market', 'may', 'methodology',\n",
              "       'milestone', 'millions', 'model', 'models', 'more', 'must',\n",
              "       'named', 'nature', 'nevertheless', 'new', 'next', 'nightmare',\n",
              "       'no', 'not', 'number', 'of', 'on', 'opportunity', 'or', 'other',\n",
              "       'outcome', 'own', 'parameters', 'perform', 'performance',\n",
              "       'performing', 'physical', 'place', 'placement', 'planning',\n",
              "       'player', 'power', 'powerful', 'privacy', 'processing',\n",
              "       'professional', 'project', 'published', 'real', 'referred',\n",
              "       'remember', 'requirements', 'revolution', 'running', 'same',\n",
              "       'satisfied', 'see', 'sent', 'series', 'significantly',\n",
              "       'smartphones', 'software', 'started', 'statement', 'step', 'story',\n",
              "       'such', 'sword', 'team', 'tech', 'technology', 'tensor',\n",
              "       'tensorflow', 'that', 'the', 'their', 'them', 'there', 'they',\n",
              "       'this', 'tightly', 'titles', 'to', 'tpu', 'training', 'try',\n",
              "       'unit', 'us', 'used', 'users', 'using', 'various', 'want', 'was',\n",
              "       'we', 'welcome', 'well', 'when', 'where', 'while', 'why', 'will',\n",
              "       'with', 'working', 'would', 'years', 'you'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7f4kbr5TIPQI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}